//
//  SpeechRecognitionService.swift
//  LearnTheCharacters
//
//  Created by Claude on 17/11/2025.
//

import Foundation
import Speech
import AVFoundation
import Combine

// Helper pour logs avec timestamp
private func logWithTime(_ message: String) {
    let formatter = DateFormatter()
    formatter.dateFormat = "HH:mm:ss.SSS"
    let timestamp = formatter.string(from: Date())
    print("[\(timestamp)] \(message)")
}

class SpeechRecognitionService: ObservableObject {
    static let shared = SpeechRecognitionService()

    @Published var isRecording = false
    @Published var recognizedText = ""
    @Published var authorizationStatus: SFSpeechRecognizerAuthorizationStatus = .notDetermined

    private var speechRecognizer: SFSpeechRecognizer?
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?
    private let audioEngine = AVAudioEngine()
    private var recordingStartTime: Date?
    private var minimumRecordingDuration: TimeInterval = 1.0 // 1 seconde minimum

    private init() {
        // Initialisation avec le chinois mandarin
        speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "zh-CN"))

        // Pr√©-initialiser l'audio session ET l'audio engine EN MODE MEASUREMENT pour √©viter le d√©lai
        DispatchQueue.global(qos: .userInitiated).async {
            // Petit d√©lai pour laisser l'app se charger
            Thread.sleep(forTimeInterval: 0.5)

            do {
                let audioSession = AVAudioSession.sharedInstance()
                // IMPORTANT : Utiliser .measurement d√®s le d√©part
                try audioSession.setCategory(.playAndRecord, mode: .measurement, options: [.defaultToSpeaker, .allowBluetoothA2DP])
                try audioSession.setActive(true)

                // FORCER l'initialisation en acc√©dant aux propri√©t√©s
                let _ = audioSession.category
                let _ = audioSession.mode
                let _ = audioSession.currentRoute
                let _ = audioSession.sampleRate

                logWithTime("‚úÖ Audio session pr√©-initialis√©e")

                // CRITIQUE: Pr√©-initialiser l'audio engine et forcer l'acc√®s au inputNode
                // C'est ici que se produit le d√©lai de 4+ secondes √† la premi√®re utilisation
                let inputNode = self.audioEngine.inputNode
                let _ = inputNode.outputFormat(forBus: 0)
                self.audioEngine.prepare()

                logWithTime("‚úÖ Audio engine + inputNode pr√©-initialis√©s")
            } catch {
                print("‚ö†Ô∏è Erreur pr√©-initialisation audio session/engine: \(error)")
            }
        }
    }

    // MARK: - Autorisation

    func requestAuthorization(completion: @escaping (Bool) -> Void) {
        SFSpeechRecognizer.requestAuthorization { status in
            DispatchQueue.main.async {
                self.authorizationStatus = status
                completion(status == .authorized)
            }
        }
    }

    // MARK: - Reconnaissance vocale

    func startRecording(completion: @escaping (String, Double) -> Void) throws {
        // V√©rifier l'autorisation
        guard authorizationStatus == .authorized else {
            throw RecognitionError.notAuthorized
        }

        // Emp√™cher les d√©marrages multiples
        if isRecording {
            print("‚ö†Ô∏è Enregistrement d√©j√† en cours, ignor√©")
            return
        }

        logWithTime("üé§ D√©marrage de l'enregistrement...")

        // Annuler la t√¢che en cours si elle existe
        if let task = recognitionTask {
            task.cancel()
            recognitionTask = nil
        }
        logWithTime("  ‚Ü≥ T√¢che pr√©c√©dente nettoy√©e")

        // S'assurer que la session audio est active (d√©j√† configur√©e en init)
        let audioSession = AVAudioSession.sharedInstance()
        logWithTime("  ‚Ü≥ Audio session obtenue")

        // Simplement activer si n√©cessaire (category et mode d√©j√† configur√©s)
        if !audioSession.isOtherAudioPlaying {
            logWithTime("  ‚Ü≥ Activation de la session...")
            try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
            logWithTime("  ‚Ü≥ Session activ√©e")
        } else {
            logWithTime("  ‚Ü≥ Session d√©j√† active")
        }

        logWithTime("üéß Session audio pr√™te")

        // Nettoyer l'audio engine s'il est en cours
        logWithTime("  ‚Ü≥ V√©rification audio engine...")
        let inputNode = audioEngine.inputNode
        if audioEngine.isRunning {
            logWithTime("  ‚Ü≥ Arr√™t audio engine en cours...")
            audioEngine.stop()
            inputNode.removeTap(onBus: 0)
            Thread.sleep(forTimeInterval: 0.1)
            logWithTime("  ‚Ü≥ Audio engine arr√™t√©")
        }

        // Cr√©er la requ√™te de reconnaissance
        logWithTime("  ‚Ü≥ Cr√©ation de la requ√™te de reconnaissance...")
        recognitionRequest = SFSpeechAudioBufferRecognitionRequest()
        guard let recognitionRequest = recognitionRequest else {
            throw RecognitionError.unableToCreateRequest
        }
        logWithTime("  ‚Ü≥ Requ√™te cr√©√©e")

        recognitionRequest.shouldReportPartialResults = true

        // Augmenter le timeout et d√©tecter la fin de parole plus tard
        if #available(iOS 16, *) {
            recognitionRequest.addsPunctuation = false
        }

        // Configuration pour reconnaissance chinoise optimis√©e
        recognitionRequest.taskHint = .dictation

        // Forcer la reconnaissance on-device pour de meilleures performances
        // (Plus rapide, fonctionne hors ligne, pas de latence r√©seau)
        if #available(iOS 17, *) {
            recognitionRequest.requiresOnDeviceRecognition = true
            print("üì± Mode on-device (rapide et local)")
        }

        // Variable pour stocker le meilleur r√©sultat
        var bestResult: (text: String, confidence: Double) = ("", 0.0)

        // Cr√©er la t√¢che de reconnaissance
        recognitionTask = speechRecognizer?.recognitionTask(with: recognitionRequest) { result, error in
            var isFinal = false

            if let result = result {
                let transcription = result.bestTranscription.formattedString
                let confidence = result.bestTranscription.segments.first?.confidence ?? 0.0

                // V√©rifier si c'est une reconnaissance on-device ou serveur
                if #available(iOS 17, *) {
                    let isOnDevice = result.bestTranscription.segments.first?.alternativeSubstrings.isEmpty ?? true
                    print("üîç Reconnaissance: \(isOnDevice ? "üì± On-Device" : "‚òÅÔ∏è Cloud")")
                }

                DispatchQueue.main.async {
                    self.recognizedText = transcription
                    print("üìù Reconnu: '\(transcription)' (confiance: \(confidence))")
                }

                // Garder le meilleur r√©sultat
                if !transcription.isEmpty && Double(confidence) > bestResult.confidence {
                    bestResult = (transcription, Double(confidence))
                }

                isFinal = result.isFinal

                if isFinal {
                    print("‚úÖ Reconnaissance finale: '\(transcription)'")
                    completion(transcription, Double(confidence))
                }
            }

            if let error = error {
                let nsError = error as NSError
                print("‚ùå Erreur reconnaissance: \(error.localizedDescription)")
                print("   Code d'erreur: \(nsError.code)")

                // V√©rifier si c'est une erreur r√©seau
                // Codes d'erreur Speech Framework :
                // - 1101: Network issue (server unreachable)
                // - 1110: No speech detected (PAS une erreur r√©seau!)
                // - 203: Connection failed
                let isNetworkError = nsError.domain == NSURLErrorDomain ||
                                    nsError.code == 1101 || // Network/Server issue
                                    nsError.code == 203     // Connection failed

                // Code 1110 = No speech detected (erreur utilisateur, pas r√©seau)
                let isNoSpeechError = nsError.code == 1110

                if isNoSpeechError {
                    print("üé§ Aucune parole d√©tect√©e - V√©rifiez votre microphone ou parlez plus fort")
                } else if isNetworkError {
                    print("üåê Erreur r√©seau d√©tect√©e (ne devrait pas arriver en mode on-device)")
                }

                // M√™me en cas d'erreur, utiliser le meilleur r√©sultat partiel si disponible
                if !bestResult.text.isEmpty {
                    print("üìã Utilisation du meilleur r√©sultat partiel: '\(bestResult.text)'")
                    completion(bestResult.text, bestResult.confidence)
                } else {
                    print("‚ö†Ô∏è Aucun r√©sultat partiel disponible")
                }
            }

            if error != nil || isFinal {
                self.audioEngine.stop()
                inputNode.removeTap(onBus: 0)

                self.recognitionRequest = nil
                self.recognitionTask = nil

                DispatchQueue.main.async {
                    self.isRecording = false
                }
            }
        }

        // Utiliser le format natif de l'input node
        let recordingFormat = inputNode.outputFormat(forBus: 0)

        print("üéôÔ∏è Format d'enregistrement: \(recordingFormat.sampleRate)Hz, \(recordingFormat.channelCount) canaux")

        inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { buffer, _ in
            // V√©rifier que le buffer contient des donn√©es avant de l'envoyer
            guard buffer.floatChannelData != nil else { return }
            let frameLength = buffer.frameLength

            // Ignorer les buffers vides
            if frameLength > 0 {
                recognitionRequest.append(buffer)
            }
        }

        // Marquer comme en enregistrement AVANT de d√©marrer
        DispatchQueue.main.async {
            self.isRecording = true
            self.recognizedText = ""
        }

        // Enregistrer l'heure de d√©but
        recordingStartTime = Date()

        // D√©marrer l'engine audio
        audioEngine.prepare()
        try audioEngine.start()

        logWithTime("‚úÖ Enregistrement actif, en attente de parole...")
    }

    func stopRecording() {
        guard isRecording else {
            print("‚ö†Ô∏è Pas d'enregistrement en cours")
            return
        }

        // V√©rifier la dur√©e minimum
        if let startTime = recordingStartTime {
            let duration = Date().timeIntervalSince(startTime)
            print("üõë Arr√™t demand√© - Dur√©e: \(String(format: "%.2f", duration))s")

            if duration < minimumRecordingDuration {
                print("‚è±Ô∏è Dur√©e trop courte, attente \(minimumRecordingDuration)s minimum...")
                // Attendre le temps restant
                let waitTime = minimumRecordingDuration - duration
                DispatchQueue.main.asyncAfter(deadline: .now() + waitTime) {
                    self.finishRecording()
                }
                return
            }
        }

        finishRecording()
    }

    private func finishRecording() {
        print("üèÅ Fin de l'enregistrement")

        // Terminer l'enregistrement audio proprement
        recognitionRequest?.endAudio()

        // Laisser plus de temps pour le traitement (1.5s au lieu de 0.5s)
        DispatchQueue.main.asyncAfter(deadline: .now() + 1.5) {
            // Arr√™ter l'audio engine AVANT de retirer le tap pour √©viter le warning buffer
            if self.audioEngine.isRunning {
                self.audioEngine.stop()

                // Petit d√©lai pour laisser l'engine se stabiliser
                DispatchQueue.main.asyncAfter(deadline: .now() + 0.1) {
                    // V√©rifier que le tap existe avant de le retirer
                    let inputNode = self.audioEngine.inputNode
                    if inputNode.numberOfInputs > 0 {
                        inputNode.removeTap(onBus: 0)
                    }
                }
            }

            self.recognitionTask?.finish()

            self.recognitionRequest = nil
            self.recognitionTask = nil

            self.isRecording = false
            self.recordingStartTime = nil

            // Garder le mode .measurement pour le prochain enregistrement (pas de reconfiguration)
            // La session reste active et pr√™te
            print("‚úÖ Enregistrement termin√©, session audio restaur√©e")
        }
    }

    // MARK: - Validation prononciation

    func validatePronunciation(expected: String, recognized: String, difficulty: GameSession.Difficulty = .intermediate, acceptedAlternatives: [String] = []) -> PronunciationResult {
        // Normalisation des textes
        let normalizedExpected = expected.trimmingCharacters(in: .whitespacesAndNewlines).lowercased()
        let normalizedRecognized = recognized.trimmingCharacters(in: .whitespacesAndNewlines).lowercased()

        // Si rien n'a √©t√© reconnu
        if normalizedRecognized.isEmpty {
            return PronunciationResult(
                isCorrect: false,
                accuracy: 0.0,
                feedback: "Aucun son d√©tect√©"
            )
        }

        // V√©rification exacte
        if normalizedExpected == normalizedRecognized {
            return PronunciationResult(isCorrect: true, accuracy: 1.0, feedback: "Parfait!")
        }

        // V√©rification des alternatives (ex: "14" pour "ÂçÅÂõõ")
        print("üîç V√©rification alternatives pour '\(normalizedRecognized)'")
        print("üìã Alternatives disponibles: \(acceptedAlternatives)")
        for alternative in acceptedAlternatives {
            let normalizedAlt = alternative.trimmingCharacters(in: .whitespacesAndNewlines).lowercased()
            print("   Comparaison: '\(normalizedAlt)' == '\(normalizedRecognized)' ‚Üí \(normalizedAlt == normalizedRecognized)")
            if normalizedAlt == normalizedRecognized {
                print("‚úÖ Alternative trouv√©e!")
                return PronunciationResult(isCorrect: true, accuracy: 1.0, feedback: "Correct!")
            }
        }

        // V√©rification sp√©ciale pour les nombres : si l'utilisateur dit un nombre arabe
        // et que le caract√®re attendu est un nombre chinois, extraire et comparer
        if let recognizedNumber = Int(normalizedRecognized) {
            print("üî¢ Nombre d√©tect√©: \(recognizedNumber)")

            // Essayer d'extraire un nombre depuis les alternatives (traductions)
            for alternative in acceptedAlternatives {
                // Chercher des nombres dans les alternatives
                if let altNumber = Int(alternative.trimmingCharacters(in: .whitespacesAndNewlines)) {
                    print("   Comparaison nombres: \(altNumber) == \(recognizedNumber) ‚Üí \(altNumber == recognizedNumber)")
                    if altNumber == recognizedNumber {
                        print("‚úÖ Nombre correspondant trouv√©!")
                        return PronunciationResult(isCorrect: true, accuracy: 1.0, feedback: "Correct!")
                    }
                }

                // Chercher aussi la correspondance avec les noms fran√ßais de nombres
                let numberWords = [
                    "z√©ro": 0, "un": 1, "deux": 2, "trois": 3, "quatre": 4, "cinq": 5,
                    "six": 6, "sept": 7, "huit": 8, "neuf": 9, "dix": 10,
                    "onze": 11, "douze": 12, "treize": 13, "quatorze": 14, "quinze": 15,
                    "seize": 16, "dix-sept": 17, "dix-huit": 18, "dix-neuf": 19, "vingt": 20
                ]

                let normalizedAlt = alternative.trimmingCharacters(in: .whitespacesAndNewlines).lowercased()
                if let altNumber = numberWords[normalizedAlt], altNumber == recognizedNumber {
                    print("‚úÖ Nombre fran√ßais '\(normalizedAlt)' correspond √† \(recognizedNumber)")
                    return PronunciationResult(isCorrect: true, accuracy: 1.0, feedback: "Correct!")
                }
            }
        }

        // V√©rification des homophones chinois (m√™me prononciation mais caract√®re diff√©rent)
        // Ex: Áîµ (di√†n) reconnu au lieu de Â∫ó (di√†n)
        if isChineseCharacter(normalizedRecognized) && isChineseCharacter(normalizedExpected) {
            // Si les deux sont des caract√®res chinois, v√©rifier si c'est un homophone via le pinyin
            // On accepte si le pinyin de l'alternative correspond
            let recognizedWithoutTones = removeTones(from: normalizedRecognized)

            // V√©rifier si le pinyin attendu (sans tons) correspond
            for alternative in acceptedAlternatives {
                let altWithoutTones = removeTones(from: alternative.lowercased())
                if altWithoutTones == recognizedWithoutTones && !altWithoutTones.isEmpty {
                    print("‚ö†Ô∏è Homophone d√©tect√©: '\(normalizedRecognized)' a la m√™me base que '\(normalizedExpected)'")

                    // V√©rifier si les tons sont corrects (comparaison exacte avec le pinyin)
                    let exactPinyinMatch = acceptedAlternatives.contains { alt in
                        alt.lowercased() == normalizedRecognized.lowercased()
                    }

                    if exactPinyinMatch {
                        // Les tons sont corrects mais c'est le mauvais caract√®re (homophone parfait)
                        print("‚úÖ Tons corrects pour l'homophone")
                        return PronunciationResult(
                            isCorrect: true,
                            accuracy: 0.85,
                            feedback: "Bons tons, mais attention au caract√®re!"
                        )
                    } else {
                        // Les tons sont probablement incorrects
                        print("‚ö†Ô∏è Tons potentiellement incorrects")
                        return PronunciationResult(
                            isCorrect: true,
                            accuracy: 0.6,
                            feedback: "Attention aux tons!"
                        )
                    }
                }
            }
        }

        // V√©rification suppl√©mentaire : comparer le pinyin attendu avec le texte reconnu
        // pour d√©tecter les prononciations approximatives (ex: "dian" vs "di√†n")
        for alternative in acceptedAlternatives {
            let altWithoutTones = removeTones(from: alternative.lowercased())
            let recognizedWithoutTones = removeTones(from: normalizedRecognized)

            // Si le pinyin sans tons correspond (ex: "dian" == "dian")
            if !altWithoutTones.isEmpty && altWithoutTones == recognizedWithoutTones {
                print("üîç Pinyin sans tons correspond: '\(recognizedWithoutTones)'")

                // V√©rifier si les tons correspondent exactement
                if alternative.lowercased() == normalizedRecognized {
                    print("‚úÖ Pinyin avec tons parfait!")
                    return PronunciationResult(
                        isCorrect: true,
                        accuracy: 0.95,
                        feedback: "Excellent! Tons parfaits!"
                    )
                } else {
                    // Base correcte mais tons approximatifs
                    print("‚ö†Ô∏è Base correcte mais tons √† am√©liorer")

                    // Selon la difficult√©, accepter ou non
                    let shouldAccept = difficulty == .beginner || difficulty == .intermediate

                    return PronunciationResult(
                        isCorrect: shouldAccept,
                        accuracy: 0.7,
                        feedback: shouldAccept ? "Bien! Attention aux tons." : "Presque! V√©rifiez les tons."
                    )
                }
            }
        }

        // Seuils de tol√©rance selon la difficult√©
        let (acceptanceThreshold, nearThreshold) = difficulty.pronunciationThresholds

        // V√©rification partielle (similitude)
        let similarity = calculateSimilarity(normalizedExpected, normalizedRecognized)

        print("üéØ Similarit√© calcul√©e: \(String(format: "%.2f", similarity)) | Seuil d'acceptation: \(String(format: "%.2f", acceptanceThreshold))")

        if similarity >= acceptanceThreshold {
            return PronunciationResult(
                isCorrect: true,
                accuracy: similarity,
                feedback: "Tr√®s bien!"
            )
        } else if similarity >= nearThreshold {
            return PronunciationResult(
                isCorrect: false,
                accuracy: similarity,
                feedback: "Presque! R√©essayez."
            )
        } else {
            return PronunciationResult(
                isCorrect: false,
                accuracy: similarity,
                feedback: "Essayez encore."
            )
        }
    }

    private func calculateSimilarity(_ str1: String, _ str2: String) -> Double {
        // Algorithme simple de distance de Levenshtein normalis√©e
        let distance = levenshteinDistance(str1, str2)
        let maxLength = max(str1.count, str2.count)
        guard maxLength > 0 else { return 1.0 }
        return 1.0 - (Double(distance) / Double(maxLength))
    }

    private func levenshteinDistance(_ s1: String, _ s2: String) -> Int {
        let m = s1.count
        let n = s2.count
        var matrix = [[Int]](repeating: [Int](repeating: 0, count: n + 1), count: m + 1)

        for i in 0...m {
            matrix[i][0] = i
        }
        for j in 0...n {
            matrix[0][j] = j
        }

        for i in 1...m {
            for j in 1...n {
                let cost = s1[s1.index(s1.startIndex, offsetBy: i - 1)] ==
                           s2[s2.index(s2.startIndex, offsetBy: j - 1)] ? 0 : 1
                matrix[i][j] = min(
                    matrix[i - 1][j] + 1,
                    matrix[i][j - 1] + 1,
                    matrix[i - 1][j - 1] + cost
                )
            }
        }

        return matrix[m][n]
    }

    private func isChineseCharacter(_ text: String) -> Bool {
        // V√©rifier si le texte contient des caract√®res chinois
        let chineseRange = text.unicodeScalars.contains { scalar in
            (0x4E00...0x9FFF).contains(scalar.value) || // CJK Unified Ideographs
            (0x3400...0x4DBF).contains(scalar.value) || // CJK Extension A
            (0x20000...0x2A6DF).contains(scalar.value)  // CJK Extension B
        }
        return chineseRange
    }

    private func removeTones(from text: String) -> String {
        // Supprimer les tons du pinyin ou nettoyer le texte
        // Pour simplifier, on garde juste les lettres et espaces
        let cleaned = text.lowercased()
            .replacingOccurrences(of: "ƒÅ", with: "a")
            .replacingOccurrences(of: "√°", with: "a")
            .replacingOccurrences(of: "«é", with: "a")
            .replacingOccurrences(of: "√†", with: "a")
            .replacingOccurrences(of: "ƒì", with: "e")
            .replacingOccurrences(of: "√©", with: "e")
            .replacingOccurrences(of: "ƒõ", with: "e")
            .replacingOccurrences(of: "√®", with: "e")
            .replacingOccurrences(of: "ƒ´", with: "i")
            .replacingOccurrences(of: "√≠", with: "i")
            .replacingOccurrences(of: "«ê", with: "i")
            .replacingOccurrences(of: "√¨", with: "i")
            .replacingOccurrences(of: "≈ç", with: "o")
            .replacingOccurrences(of: "√≥", with: "o")
            .replacingOccurrences(of: "«í", with: "o")
            .replacingOccurrences(of: "√≤", with: "o")
            .replacingOccurrences(of: "≈´", with: "u")
            .replacingOccurrences(of: "√∫", with: "u")
            .replacingOccurrences(of: "«î", with: "u")
            .replacingOccurrences(of: "√π", with: "u")
            .replacingOccurrences(of: "«ñ", with: "v")
            .replacingOccurrences(of: "«ò", with: "v")
            .replacingOccurrences(of: "«ö", with: "v")
            .replacingOccurrences(of: "«ú", with: "v")
            .replacingOccurrences(of: "√º", with: "v")
        return cleaned
    }

    enum RecognitionError: Error {
        case notAuthorized
        case unableToCreateRequest
        case audioEngineError
    }
}

struct PronunciationResult {
    let isCorrect: Bool
    let accuracy: Double // 0.0 to 1.0
    let feedback: String
}
